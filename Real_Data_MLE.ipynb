{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97154bc1",
   "metadata": {},
   "source": [
    "## File includes codes to run MLE on the 4 models (multiple sampling strategies used for the coarse grid search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115aabc9",
   "metadata": {},
   "source": [
    "### G1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b368957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "from scipy.optimize import minimize\n",
    "from numpy.polynomial import chebyshev\n",
    "from scipy.special import gegenbauer\n",
    "\n",
    "_EPS = 1e-12\n",
    "d = 2  # dimension of the grid\n",
    "p = 1  # positive odd integer\n",
    "\n",
    "# ============================================================\n",
    "# PSD helper\n",
    "# ============================================================\n",
    "def make_psd(C, eps=1e-9):\n",
    "    C = 0.5 * (C + C.T)\n",
    "    w, V = np.linalg.eigh(C)\n",
    "    w = np.maximum(w, eps)\n",
    "    return (V * w) @ V.T\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Even / odd kernels\n",
    "# ============================================================\n",
    "def G_even(h, a):\n",
    "    return np.exp(-(h @ h) / (a * a + _EPS))\n",
    "\n",
    "\n",
    "def G_odd(h, a, u0):\n",
    "    hnorm = (h @ h) ** 0.5\n",
    "    if hnorm == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        if d == 2:\n",
    "            # NOTE: this matches your original usage\n",
    "            Tp = chebyshev.Chebyshev.basis(p)#chebyshev.Chebyshev(p)\n",
    "            return ((-1) ** ((p - 1) / 2)) * (a ** (1 - p)) * Tp((h @ u0) / hnorm) * np.exp(\n",
    "                -(h @ h) / (2.0 * a + _EPS)\n",
    "            )\n",
    "        \n",
    "        #else:\n",
    "        #use the formula for d>2\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# C2 block and full covariance\n",
    "# ============================================================\n",
    "def C2_block(h, a11, a22, a12, rho, s1, s2, u0):\n",
    "    C11 = s1 * s1 * G_even(h, a11)\n",
    "    C22 = s2 * s2 * G_even(h, a22)\n",
    "\n",
    "    C12 = rho * s1 * s2 * G_odd(h, a12, u0)\n",
    "    C21 = -C12\n",
    "\n",
    "    return np.array([[C11, C12],\n",
    "                     [C21, C22]])\n",
    "\n",
    "\n",
    "def build_cov_C2(loc, a11, a22, a12, rho, s1, s2, u0):\n",
    "    N = len(loc)\n",
    "    C = np.zeros((2 * N, 2 * N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            h = loc[j] - loc[i]\n",
    "            block = C2_block(h, a11, a22, a12, rho, s1, s2, u0)\n",
    "            C[2 * i:2 * i + 2, 2 * j:2 * j + 2] = block\n",
    "    return make_psd(C)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# NLL with multiple time replicates (full parameter vector)\n",
    "# ============================================================\n",
    "def total_nll_full_params(params, loc, y_list, s1, s2, u0):\n",
    "    a11, a22, a12, rho = params\n",
    "\n",
    "    # Basic constraints\n",
    "    if a11 <= 0 or a22 <= 0 or a12 <= 0 or abs(rho) >= 1:\n",
    "        return 1e20\n",
    "\n",
    "    C = build_cov_C2(loc, a11, a22, a12, rho, s1, s2, u0)\n",
    "    if np.isnan(C).any() or np.isinf(C).any():\n",
    "        return 1e20\n",
    "\n",
    "    try:\n",
    "        cF = cho_factor(C, check_finite=False)\n",
    "        logdet = 2.0 * np.sum(np.log(np.diag(cF[0])))\n",
    "    except Exception:\n",
    "        return 1e20\n",
    "\n",
    "    m = C.shape[0]        # 2N\n",
    "    R = len(y_list)       # number of time replicates\n",
    "\n",
    "    quad_sum = 0.0\n",
    "    try:\n",
    "        for y in y_list:\n",
    "            alpha = cho_solve(cF, y, check_finite=False)\n",
    "            quad_sum += float(y @ alpha)\n",
    "    except Exception:\n",
    "        return 1e20\n",
    "\n",
    "    nll = 0.5 * (quad_sum + R * logdet + R * m * np.log(2.0 * np.pi))\n",
    "    return nll\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Joint MLE with grid-search-based initialization\n",
    "# ============================================================\n",
    "def coordinate_mle_C2_multi(loc, y_list, s1, s2, u0, init):\n",
    "    \"\"\"\n",
    "    Joint MLE of (a11, a22, a12_even, a12_odd, theta, rho) with:\n",
    "      1) pseudo-grid search over bounds to find a good starting point\n",
    "      2) L-BFGS-B optimization from that starting point\n",
    "\n",
    "    'init' is still accepted and included as one of the candidate starting points.\n",
    "    \"\"\"\n",
    "    # Bounds (Adjust accordingly)\n",
    "    bounds = [\n",
    "        (50.0, 4000.0),      # a11\n",
    "        (50.0, 4000.0),      # a22\n",
    "        (50.0, 4000.0),      # a12\n",
    "        (-0.99, 0.99)        # rho\n",
    "    ]\n",
    "\n",
    "    # ---- 1) Pseudo-grid search with logging ----\n",
    "    n_grid = 7           # ~7 values per parameter across its bounds\n",
    "    n_candidates = 200   # number of random combinations from that grid\n",
    "\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    grid_vals = []\n",
    "    for (low, high) in bounds:\n",
    "        grid_vals.append(np.linspace(low, high, n_grid))\n",
    "\n",
    "    # Start with the user-provided init as a candidate (if valid)\n",
    "    best_params = np.array(init, dtype=float)\n",
    "    best_nll = total_nll_full_params(best_params, loc, y_list, s1, s2, u0)\n",
    "\n",
    "    print(\"Starting grid search for initial parameters...\")\n",
    "    print(f\"Initial candidate from 'init': NLL = {best_nll:.3f}\")\n",
    "\n",
    "    for cand_i in range(n_candidates):\n",
    "        idxs = rng.integers(0, n_grid, size=len(bounds))\n",
    "        candidate = np.array([grid_vals[k][idxs[k]] for k in range(len(bounds))], dtype=float)\n",
    "        nll_val = total_nll_full_params(candidate, loc, y_list, s1, s2, u0)\n",
    "\n",
    "        if nll_val < best_nll:\n",
    "            best_nll = nll_val\n",
    "            best_params = candidate\n",
    "\n",
    "        # Simple progress logging\n",
    "        if (cand_i + 1) % 50 == 0 or cand_i == 0:\n",
    "            print(\n",
    "                f\"Grid search candidate {cand_i + 1}/{n_candidates} \"\n",
    "                f\"| current best NLL = {best_nll:.3f}\"\n",
    "            )\n",
    "\n",
    "    print(\"Best grid-search params:\", best_params)\n",
    "    print(\"Best grid-search NLL:\", best_nll)\n",
    "\n",
    "    # ---- 2) Local optimization from best grid-search point ----\n",
    "    print(\"\\nStarting local optimization from best grid-search point...\")\n",
    "    res = minimize(\n",
    "        lambda params: total_nll_full_params(params, loc, y_list, s1, s2, u0),\n",
    "        x0=best_params,\n",
    "        bounds=bounds,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={'maxiter': 100}\n",
    "    )\n",
    "\n",
    "    print(\"Optimization success:\", res.success)\n",
    "    print(\"Message:\", res.message)\n",
    "    print(\"Final params:\", res.x)\n",
    "    print(\"Final NLL:\", res.fun)\n",
    "\n",
    "    a11_hat, a22_hat, a12_hat, rho_hat = res.x\n",
    "    return a11_hat, a22_hat, a12_hat, rho_hat\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "print(\"Loading multi-time U/V dataset...\")\n",
    "df = pd.read_csv(\"uv_wind_multi_for_C2.csv\", parse_dates=[\"datetime\"])\n",
    "print(\"Total rows:\", len(df))\n",
    "\n",
    "# 1) Build spatial grid from the FIRST time slice\n",
    "times = np.sort(df[\"datetime\"].unique())\n",
    "t0 = times[0]\n",
    "df0 = df[df[\"datetime\"] == t0].copy()\n",
    "\n",
    "# Sort by (lat, lon) to get consistent ordering\n",
    "df0 = df0.sort_values([\"latitude\", \"longitude\"]).reset_index(drop=True)\n",
    "\n",
    "lat0 = df0[\"latitude\"].to_numpy()\n",
    "lon0 = df0[\"longitude\"].to_numpy()\n",
    "\n",
    "# Convert deg -> km \n",
    "lat_mean = np.mean(lat0)\n",
    "x_km = 111.0 * lon0 * np.cos(np.radians(lat_mean))\n",
    "y_km = 111.0 * lat0\n",
    "loc = np.column_stack([x_km, y_km])\n",
    "N = loc.shape[0]\n",
    "\n",
    "print(\"Spatial grid size N =\", N)\n",
    "\n",
    "# 2) Build list of y_t vectors across time replicates\n",
    "y_list = []\n",
    "max_reps = 20  # upper limit on number of time replicates\n",
    "\n",
    "for tt in times:\n",
    "    if len(y_list) >= max_reps:\n",
    "        break\n",
    "\n",
    "    df_t = df[df[\"datetime\"] == tt].copy()\n",
    "    # Ensure same grid/order as df0 by merging\n",
    "    df_t = df_t.merge(\n",
    "        df0[[\"latitude\", \"longitude\"]],\n",
    "        on=[\"latitude\", \"longitude\"],\n",
    "        how=\"right\",\n",
    "        sort=False\n",
    "    )\n",
    "\n",
    "    # If any missing, skip this time\n",
    "    if df_t[\"u_std\"].isna().any() or df_t[\"v_std\"].isna().any():\n",
    "        continue\n",
    "\n",
    "    df_t = df_t.sort_values([\"latitude\", \"longitude\"]).reset_index(drop=True)\n",
    "\n",
    "    Y1 = df_t[\"u_std\"].to_numpy()\n",
    "    Y2 = df_t[\"v_std\"].to_numpy()\n",
    "\n",
    "    if len(Y1) != N or len(Y2) != N:\n",
    "        continue\n",
    "\n",
    "    y_t = np.zeros(2 * N)\n",
    "    y_t[0::2] = Y1\n",
    "    y_t[1::2] = Y2\n",
    "\n",
    "    y_list.append(y_t)\n",
    "\n",
    "R = len(y_list)\n",
    "print(\"Number of time replicates used:\", R)\n",
    "\n",
    "if R == 0:\n",
    "    raise RuntimeError(\"No complete time replicate found.\")\n",
    "\n",
    "# 3) Fit C2 with replicates\n",
    "s1 = s2 = 1.0\n",
    "u0 = np.array([1.0, 0.0])  # east–west\n",
    "\n",
    "print(\"\\nFitting C2 model with multiple time replicates...\\n\")\n",
    "\n",
    "init_params = (200.0, 200.0, 200.0, 0.5)\n",
    "\n",
    "a11_hat, a22_hat, a12_hat, rho_hat = coordinate_mle_C2_multi(\n",
    "    loc, y_list, s1, s2, u0, init_params\n",
    ")\n",
    "\n",
    "print(\"\\n===== FINAL ESTIMATES (C2, multi-time U/V) =====\")\n",
    "print(\"a11       =\", a11_hat)\n",
    "print(\"a22       =\", a22_hat)\n",
    "print(\"a12  =\", a12_hat)\n",
    "print(\"rho       =\", rho_hat)\n",
    "\n",
    "# 4) Model fit statistics: full NLL, AIC, BIC\n",
    "final_params = (a11_hat, a22_hat, a12_hat, rho_hat)\n",
    "NLL = total_nll_full_params(final_params, loc, y_list, s1, s2, u0)\n",
    "\n",
    "m = 2 * N\n",
    "k = 6\n",
    "n_obs = R * m\n",
    "\n",
    "AIC = 2 * k + 2 * NLL\n",
    "BIC = k * np.log(n_obs) + 2 * NLL\n",
    "\n",
    "print(\"\\n===== MODEL FIT (C2, multi-time U/V) =====\")\n",
    "print(\"NLL =\", NLL)\n",
    "print(\"AIC =\", AIC)\n",
    "print(\"BIC =\", BIC)\n",
    "print(\"N   =\", N, \"locations; R =\", R, \"replicates; total obs =\", n_obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02102fe",
   "metadata": {},
   "source": [
    "## G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5eca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "from scipy.optimize import minimize\n",
    "from numpy.polynomial import chebyshev\n",
    "from scipy.special import gegenbauer\n",
    "\n",
    "_EPS = 1e-12\n",
    "d = 2  # dimension of the grid\n",
    "p = 1  # positive odd integer\n",
    "\n",
    "# ============================================================\n",
    "# PSD helper\n",
    "# ============================================================\n",
    "def make_psd(C, eps=1e-9):\n",
    "    C = 0.5 * (C + C.T)\n",
    "    w, V = np.linalg.eigh(C)\n",
    "    w = np.maximum(w, eps)\n",
    "    return (V * w) @ V.T\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Even / odd kernels\n",
    "# ============================================================\n",
    "def G_even(h, a):\n",
    "    return np.exp(-(h @ h) / (a * a + _EPS))\n",
    "\n",
    "\n",
    "def G_odd(h, a, u0):\n",
    "    hnorm = (h @ h) ** 0.5\n",
    "    if hnorm == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        if d == 2:\n",
    "            # NOTE: this matches your original usage\n",
    "            Tp = chebyshev.Chebyshev.basis(p)#chebyshev.Chebyshev(p)\n",
    "            return ((-1) ** ((p - 1) / 2)) * (a ** (1 - p)) * Tp((h @ u0) / hnorm) * np.exp(\n",
    "                -(h @ h) / (2.0 * a + _EPS)\n",
    "            )\n",
    "\n",
    "        #else:\n",
    "            #Cp = gegenbauer(p, d / 2 - 1)\n",
    "            #Use the formula with the Genenbaur polynomial\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# C2 block and full covariance\n",
    "# ============================================================\n",
    "def C2_block(h, a11, a22, a12_even, a12_odd, theta, rho, s1, s2, u0):\n",
    "    C11 = s1 * s1 * G_even(h, a11)\n",
    "    C22 = s2 * s2 * G_even(h, a22)\n",
    "\n",
    "    even_part = G_even(h, a12_even)\n",
    "    odd_part = G_odd(h, a12_odd, u0)\n",
    "\n",
    "    mix_plus = (np.cos(theta))**2 * even_part + (np.sin(theta))**2 * odd_part\n",
    "    mix_minus = (np.cos(theta))**2 * even_part - (np.sin(theta))**2 * odd_part\n",
    "\n",
    "    C12 = rho * s1 * s2 * mix_plus\n",
    "    C21 = rho * s1 * s2 * mix_minus\n",
    "\n",
    "    return np.array([[C11, C12],\n",
    "                     [C21, C22]])\n",
    "\n",
    "\n",
    "def build_cov_C2(loc, a11, a22, a12_even, a12_odd, theta, rho, s1, s2, u0):\n",
    "    N = len(loc)\n",
    "    C = np.zeros((2 * N, 2 * N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            h = loc[j] - loc[i]\n",
    "            block = C2_block(h, a11, a22, a12_even, a12_odd, theta, rho, s1, s2, u0)\n",
    "            C[2 * i:2 * i + 2, 2 * j:2 * j + 2] = block\n",
    "    return make_psd(C)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# NLL with multiple time replicates (full parameter vector)\n",
    "# ============================================================\n",
    "def total_nll_full_params(params, loc, y_list, s1, s2, u0):\n",
    "    a11, a22, a12_even, a12_odd, theta, rho = params\n",
    "\n",
    "    # Basic constraints\n",
    "    if a11 <= 0 or a22 <= 0 or a12_even <= 0 or a12_odd <= 0 or abs(rho) >= 1:\n",
    "        return 1e20\n",
    "\n",
    "    C = build_cov_C2(loc, a11, a22, a12_even, a12_odd, theta, rho, s1, s2, u0)\n",
    "    if np.isnan(C).any() or np.isinf(C).any():\n",
    "        return 1e20\n",
    "\n",
    "    try:\n",
    "        cF = cho_factor(C, check_finite=False)\n",
    "        logdet = 2.0 * np.sum(np.log(np.diag(cF[0])))\n",
    "    except Exception:\n",
    "        return 1e20\n",
    "\n",
    "    m = C.shape[0]        # 2N\n",
    "    R = len(y_list)       # number of time replicates\n",
    "\n",
    "    quad_sum = 0.0\n",
    "    try:\n",
    "        for y in y_list:\n",
    "            alpha = cho_solve(cF, y, check_finite=False)\n",
    "            quad_sum += float(y @ alpha)\n",
    "    except Exception:\n",
    "        return 1e20\n",
    "\n",
    "    nll = 0.5 * (quad_sum + R * logdet + R * m * np.log(2.0 * np.pi))\n",
    "    return nll\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Joint MLE with grid-search-based initialization\n",
    "# ============================================================\n",
    "def coordinate_mle_C2_multi(loc, y_list, s1, s2, u0, init):\n",
    "    \"\"\"\n",
    "    Joint MLE of (a11, a22, a12_even, a12_odd, theta, rho) with:\n",
    "      1) pseudo-grid search over bounds to find a good starting point\n",
    "      2) L-BFGS-B optimization from that starting point\n",
    "\n",
    "    'init' is still accepted and included as one of the candidate starting points.\n",
    "    \"\"\"\n",
    "    # Bounds (same as before)\n",
    "    bounds = [\n",
    "        (50.0, 4000.0),      # a11\n",
    "        (50.0, 4000.0),      # a22\n",
    "        (50.0, 4000.0),      # a12_even\n",
    "        (50.0, 4000.0),      # a12_odd\n",
    "        (0.0, 2.0 * np.pi),  # theta\n",
    "        (-0.99, 0.99)        # rho\n",
    "    ]\n",
    "\n",
    "    # ---- 1) Pseudo-grid search with logging ----\n",
    "    n_grid = 7           # ~7 values per parameter across its bounds\n",
    "    n_candidates = 200   # number of random combinations from that grid\n",
    "\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    grid_vals = []\n",
    "    for (low, high) in bounds:\n",
    "        grid_vals.append(np.linspace(low, high, n_grid))\n",
    "\n",
    "    # Start with the user-provided init as a candidate (if valid)\n",
    "    best_params = np.array(init, dtype=float)\n",
    "    best_nll = total_nll_full_params(best_params, loc, y_list, s1, s2, u0)\n",
    "\n",
    "    print(\"Starting grid search for initial parameters...\")\n",
    "    print(f\"Initial candidate from 'init': NLL = {best_nll:.3f}\")\n",
    "\n",
    "    for cand_i in range(n_candidates):\n",
    "        idxs = rng.integers(0, n_grid, size=len(bounds))\n",
    "        candidate = np.array([grid_vals[k][idxs[k]] for k in range(len(bounds))], dtype=float)\n",
    "        nll_val = total_nll_full_params(candidate, loc, y_list, s1, s2, u0)\n",
    "\n",
    "        if nll_val < best_nll:\n",
    "            best_nll = nll_val\n",
    "            best_params = candidate\n",
    "\n",
    "        # Simple progress logging\n",
    "        if (cand_i + 1) % 50 == 0 or cand_i == 0:\n",
    "            print(\n",
    "                f\"Grid search candidate {cand_i + 1}/{n_candidates} \"\n",
    "                f\"| current best NLL = {best_nll:.3f}\"\n",
    "            )\n",
    "\n",
    "    print(\"Best grid-search params:\", best_params)\n",
    "    print(\"Best grid-search NLL:\", best_nll)\n",
    "\n",
    "    # ---- 2) Local optimization from best grid-search point ----\n",
    "    print(\"\\nStarting local optimization from best grid-search point...\")\n",
    "    res = minimize(\n",
    "        lambda params: total_nll_full_params(params, loc, y_list, s1, s2, u0),\n",
    "        x0=best_params,\n",
    "        bounds=bounds,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={'maxiter': 500}\n",
    "    )\n",
    "\n",
    "    print(\"Optimization success:\", res.success)\n",
    "    print(\"Message:\", res.message)\n",
    "    print(\"Final params:\", res.x)\n",
    "    print(\"Final NLL:\", res.fun)\n",
    "\n",
    "    a11_hat, a22_hat, a12_even_hat, a12_odd_hat, theta_hat, rho_hat = res.x\n",
    "    return a11_hat, a22_hat, a12_even_hat, a12_odd_hat, theta_hat, rho_hat\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "print(\"Loading multi-time U/V dataset...\")\n",
    "df = pd.read_csv(\"Data.csv\", parse_dates=[\"datetime\"])#load the relevant data\n",
    "print(\"Total rows:\", len(df))\n",
    "\n",
    "# 1) Build spatial grid from the FIRST time slice\n",
    "times = np.sort(df[\"datetime\"].unique())\n",
    "t0 = times[0]\n",
    "df0 = df[df[\"datetime\"] == t0].copy()\n",
    "\n",
    "# Sort by (lat, lon) to get consistent ordering\n",
    "df0 = df0.sort_values([\"latitude\", \"longitude\"]).reset_index(drop=True)\n",
    "\n",
    "lat0 = df0[\"latitude\"].to_numpy()\n",
    "lon0 = df0[\"longitude\"].to_numpy()\n",
    "\n",
    "# Convert deg -> km\n",
    "lat_mean = np.mean(lat0)\n",
    "x_km = 111.0 * lon0 * np.cos(np.radians(lat_mean))\n",
    "y_km = 111.0 * lat0\n",
    "loc = np.column_stack([x_km, y_km])\n",
    "N = loc.shape[0]\n",
    "\n",
    "print(\"Spatial grid size N =\", N)\n",
    "\n",
    "# 2) Build list of y_t vectors across time replicates\n",
    "y_list = []\n",
    "max_reps = 20  # upper limit on number of time replicates\n",
    "\n",
    "for tt in times:\n",
    "    if len(y_list) >= max_reps:\n",
    "        break\n",
    "\n",
    "    df_t = df[df[\"datetime\"] == tt].copy()\n",
    "    # Ensure same grid/order as df0 by merging\n",
    "    df_t = df_t.merge(\n",
    "        df0[[\"latitude\", \"longitude\"]],\n",
    "        on=[\"latitude\", \"longitude\"],\n",
    "        how=\"right\",\n",
    "        sort=False\n",
    "    )\n",
    "\n",
    "    # If any missing, skip this time\n",
    "    if df_t[\"u_std\"].isna().any() or df_t[\"v_std\"].isna().any():\n",
    "        continue\n",
    "\n",
    "    df_t = df_t.sort_values([\"latitude\", \"longitude\"]).reset_index(drop=True)\n",
    "\n",
    "    Y1 = df_t[\"u_std\"].to_numpy()\n",
    "    Y2 = df_t[\"v_std\"].to_numpy()\n",
    "\n",
    "    if len(Y1) != N or len(Y2) != N:\n",
    "        continue\n",
    "\n",
    "    y_t = np.zeros(2 * N)\n",
    "    y_t[0::2] = Y1\n",
    "    y_t[1::2] = Y2\n",
    "\n",
    "    y_list.append(y_t)\n",
    "\n",
    "R = len(y_list)\n",
    "print(\"Number of time replicates used:\", R)\n",
    "\n",
    "if R == 0:\n",
    "    raise RuntimeError(\"No complete time replicate found.\")\n",
    "\n",
    "# 3) Fit C2 with replicates\n",
    "s1 = s2 = 1.0\n",
    "u0 = np.array([1.0, 0.0])  # east–west\n",
    "\n",
    "print(\"\\nFitting C2 model with multiple time replicates...\\n\")\n",
    "\n",
    "init_params = (200.0, 200.0, 200.0, 200.0, np.pi, 0.5)\n",
    "\n",
    "a11_hat, a22_hat, a12_even_hat, a12_odd_hat, theta_hat, rho_hat = coordinate_mle_C2_multi(\n",
    "    loc, y_list, s1, s2, u0, init_params\n",
    ")\n",
    "\n",
    "print(\"\\n===== FINAL ESTIMATES (C2, multi-time U/V) =====\")\n",
    "print(\"a11       =\", a11_hat)\n",
    "print(\"a22       =\", a22_hat)\n",
    "print(\"a12_even  =\", a12_even_hat)\n",
    "print(\"a12_odd   =\", a12_odd_hat)\n",
    "print(\"theta     =\", theta_hat)\n",
    "print(\"rho       =\", rho_hat)\n",
    "\n",
    "# 4) Model fit statistics: full NLL, AIC, BIC\n",
    "final_params = (a11_hat, a22_hat, a12_even_hat, a12_odd_hat, theta_hat, rho_hat)\n",
    "NLL = total_nll_full_params(final_params, loc, y_list, s1, s2, u0)\n",
    "\n",
    "m = 2 * N\n",
    "k = 6\n",
    "n_obs = R * m\n",
    "\n",
    "AIC = 2 * k + 2 * NLL\n",
    "BIC = k * np.log(n_obs) + 2 * NLL\n",
    "\n",
    "print(\"\\n===== MODEL FIT (C2, multi-time U/V) =====\")\n",
    "print(\"NLL =\", NLL)\n",
    "print(\"AIC =\", AIC)\n",
    "print(\"BIC =\", BIC)\n",
    "print(\"N   =\", N, \"locations; R =\", R, \"replicates; total obs =\", n_obs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd691be",
   "metadata": {},
   "source": [
    "## M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74997c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "from scipy.optimize import minimize\n",
    "from numpy.polynomial import chebyshev\n",
    "from scipy.special import gamma, kv\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "_EPS = 1e-12\n",
    "d = 2  \n",
    "p = 3   # odd integer\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PSD helper\n",
    "# ============================================================\n",
    "def make_psd(C, eps=1e-9):\n",
    "    C = 0.5 * (C + C.T)\n",
    "    w, V = np.linalg.eigh(C)\n",
    "    w = np.maximum(w, eps)\n",
    "    return (V * w) @ V.T\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Even / odd kernels  (Matérn-like)\n",
    "# ============================================================\n",
    "def G_even(h, a, nu):\n",
    "    hnorm = np.sqrt(h @ h)\n",
    "    if hnorm == 0:\n",
    "        return 1.0\n",
    "\n",
    "    ah = a * hnorm\n",
    "    kv_val = kv(nu, ah)\n",
    "    if not np.isfinite(kv_val) or kv_val <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    val = (2 ** (1 - nu)) / gamma(nu) * (ah ** nu) * kv_val\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "def G_odd(h, a, u0, nu):\n",
    "    hnorm = np.sqrt(h @ h)\n",
    "    if hnorm == 0:\n",
    "        return 0.0\n",
    "\n",
    "    ah = a * hnorm\n",
    "    kv_val = kv(p - nu, ah)\n",
    "    if not np.isfinite(kv_val) or kv_val <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    # correct Chebyshev polynomial T_p\n",
    "    Tp = chebyshev.Chebyshev.basis(p)\n",
    "    cosang = (h @ u0) / hnorm\n",
    "    cosang = np.clip(cosang, -1, 1)\n",
    "\n",
    "    Tval = Tp(cosang)\n",
    "\n",
    "    val = ((-1) ** ((p - 1) / 2)) * (ah ** nu) * Tval * kv_val\n",
    "    return float(val)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Covariance\n",
    "# ============================================================\n",
    "def C2_block(h, a11, a22, a12, nu11, nu22, nu12, rho, s1, s2, u0):\n",
    "    C11 = s1 * s1 * G_even(h, a11, nu11)\n",
    "    C22 = s2 * s2 * G_even(h, a22, nu22)\n",
    "    C12 = rho * s1 * s2 * G_odd(h, a12, u0, nu12)\n",
    "    C21 = -C12\n",
    "    return np.array([[C11, C12], [C21, C22]])\n",
    "\n",
    "\n",
    "def build_cov_C2(loc, a11, a22, a12, nu11, nu22, nu12, rho, s1, s2, u0):\n",
    "    N = len(loc)\n",
    "    C = np.zeros((2 * N, 2 * N))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            h = loc[j] - loc[i]\n",
    "            C[2*i:2*i+2, 2*j:2*j+2] = C2_block(h, a11, a22, a12, nu11, nu22, nu12, rho, s1, s2, u0)\n",
    "\n",
    "    return make_psd(C)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# NLL\n",
    "# ============================================================\n",
    "def total_nll_full_params(params, loc, y_list, s1, s2, u0):\n",
    "    a11, a22, a12, nu11, nu22, nu12, rho = params\n",
    "\n",
    "    if a11 <= 0 or a22 <= 0 or a12 <= 0 or abs(rho) >= 1:\n",
    "        return 1e20\n",
    "\n",
    "    # IMPORTANT: enforce ν constraints\n",
    "    if nu11 <= 0 or nu22 <= 0 or nu12 <= 0:\n",
    "        return 1e20\n",
    "\n",
    "    C = build_cov_C2(loc, a11, a22, a12, nu11, nu22, nu12, rho, s1, s2, u0)\n",
    "    if np.isnan(C).any() or np.isinf(C).any():\n",
    "        return 1e20\n",
    "\n",
    "    try:\n",
    "        cF = cho_factor(C, check_finite=False)\n",
    "        logdet = 2 * np.sum(np.log(np.diag(cF[0])))\n",
    "    except:\n",
    "        return 1e20\n",
    "\n",
    "    m = C.shape[0]\n",
    "    R = len(y_list)\n",
    "\n",
    "    quad = 0.0\n",
    "    try:\n",
    "        for y in y_list:\n",
    "            alpha = cho_solve(cF, y, check_finite=False)\n",
    "            quad += y @ alpha\n",
    "    except:\n",
    "        return 1e20\n",
    "\n",
    "    return 0.5 * (quad + R * logdet + R * m * np.log(2 * np.pi))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Joint MLE (grid search + L-BFGS-B)\n",
    "# ============================================================\n",
    "def coordinate_mle_C2_multi(loc, y_list, s1, s2, u0, init):\n",
    "    bounds = [\n",
    "        (50.0, 4000.0),   # a11\n",
    "        (50.0, 4000.0),   # a22\n",
    "        (50.0, 4000.0),   # a12\n",
    "        (0.1, 10.0),      # nu11\n",
    "        (0.1, 10.0),      # nu22\n",
    "        (0.1, 10.0),      # nu12\n",
    "        (-0.99, 0.99)     # rho\n",
    "    ]\n",
    "\n",
    "    # ---- simple grid search ----\n",
    "    n_grid = 20\n",
    "    n_candidates = 100\n",
    "    rng = np.random.default_rng(0)\n",
    "\n",
    "    grid_vals = [np.linspace(l, u, n_grid) for (l, u) in bounds]\n",
    "\n",
    "    best_params = np.array(init, float)\n",
    "    best_nll = total_nll_full_params(best_params, loc, y_list, s1, s2, u0)\n",
    "\n",
    "    print(\"Grid search start, initial NLL =\", best_nll)\n",
    "\n",
    "    for i in range(n_candidates):\n",
    "        idx = rng.integers(0, n_grid, len(bounds))\n",
    "        cand = np.array([grid_vals[k][idx[k]] for k in range(len(bounds))])\n",
    "        nll = total_nll_full_params(cand, loc, y_list, s1, s2, u0)\n",
    "\n",
    "        if nll < best_nll:\n",
    "            best_nll = nll\n",
    "            best_params = cand\n",
    "\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"Grid {i+1}/{n_candidates}, best NLL = {best_nll}\")\n",
    "\n",
    "    print(\"Best grid params:\", best_params)\n",
    "\n",
    "    # ---- L-BFGS-B ----\n",
    "    res = minimize(\n",
    "        lambda p: total_nll_full_params(p, loc, y_list, s1, s2, u0),\n",
    "        best_params,\n",
    "        bounds=bounds,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={\"maxiter\": 500}\n",
    "    )\n",
    "\n",
    "    print(\"Optimizer:\", res.message)\n",
    "    print(\"Final params:\", res.x)\n",
    "    print(\"Final NLL:\", res.fun)\n",
    "\n",
    "    return res.x\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv(\"Data.csv\", parse_dates=[\"datetime\"])\n",
    "\n",
    "times = np.sort(df[\"datetime\"].unique())\n",
    "df0 = df[df[\"datetime\"] == times[0]].sort_values([\"latitude\",\"longitude\"]).reset_index(drop=True)\n",
    "\n",
    "lat0 = df0[\"latitude\"].values\n",
    "lon0 = df0[\"longitude\"].values\n",
    "\n",
    "lat_mean = np.mean(lat0)\n",
    "x_km = 111 * lon0 * np.cos(np.radians(lat_mean))\n",
    "y_km = 111 * lat0\n",
    "loc = np.column_stack([x_km, y_km])\n",
    "##\n",
    "D = squareform(pdist(loc))          # all pairwise distances in km\n",
    "np.fill_diagonal(D, np.inf)\n",
    "nn_dists = D.min(axis=1)            # nearest neighbor distance for each location\n",
    "dist_scale = nn_dists.mean()        # average nn distance (in km)\n",
    "loc = loc / dist_scale\n",
    "\n",
    "##\n",
    "N = len(loc)\n",
    "\n",
    "# Build y vectors\n",
    "y_list = []\n",
    "for tt in times[:20]:\n",
    "    df_t = df[df[\"datetime\"] == tt].copy()\n",
    "    df_t = df_t.merge(df0[[\"latitude\",\"longitude\"]], on=[\"latitude\",\"longitude\"], how=\"right\")\n",
    "    if df_t[\"u_std\"].isna().any() or df_t[\"v_std\"].isna().any():\n",
    "        continue\n",
    "    df_t = df_t.sort_values([\"latitude\",\"longitude\"]).reset_index(drop=True)\n",
    "\n",
    "    y = np.zeros(2*N)\n",
    "    y[0::2] = df_t[\"u_std\"].values\n",
    "    y[1::2] = df_t[\"v_std\"].values\n",
    "    y_list.append(y)\n",
    "\n",
    "R = len(y_list)\n",
    "print(\"Replicates:\", R)\n",
    "\n",
    "s1 = s2 = 1.0\n",
    "u0 = np.array([1.0, 0.0])\n",
    "\n",
    "init_params = (800,800,800, 1,1,1, 0.3)\n",
    "params = coordinate_mle_C2_multi(loc, y_list, s1, s2, u0, init_params)\n",
    "\n",
    "a11_hat, a22_hat, a12_hat, nu11_hat, nu22_hat, nu12_hat, rho_hat = params\n",
    "\n",
    "print(\"\\nFinal parameters:\")\n",
    "print(params)\n",
    "\n",
    "NLL = total_nll_full_params(params, loc, y_list, s1, s2, u0)\n",
    "\n",
    "k = 7\n",
    "m = 2*N\n",
    "n_obs = R * m\n",
    "\n",
    "AIC = 2*k + 2*NLL\n",
    "BIC = k*np.log(n_obs) + 2*NLL\n",
    "\n",
    "print(\"\\nNLL =\", NLL)\n",
    "print(\"AIC =\", AIC)\n",
    "print(\"BIC =\", BIC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c1180c",
   "metadata": {},
   "source": [
    "## M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ab053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import cho_factor, cho_solve\n",
    "from scipy.optimize import minimize\n",
    "from numpy.polynomial import chebyshev\n",
    "from scipy.special import gamma, kv\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "_EPS = 1e-12\n",
    "d = 2  # dimension of the grid\n",
    "p = 5  # positive odd integer\n",
    "\n",
    "# ============================================================\n",
    "# PSD helper\n",
    "# ============================================================\n",
    "def make_psd(C, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Symmetrize and add a small nugget for numerical stability.\n",
    "    \"\"\"\n",
    "    C = 0.5 * (C + C.T)\n",
    "    C = C + eps * np.eye(C.shape[0])\n",
    "    return C\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Even / odd kernels (Matérn-type)\n",
    "# ============================================================\n",
    "def G_even(h, a, nu):\n",
    "    hnorm = (h @ h) ** 0.5\n",
    "    if hnorm == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        x = a * hnorm\n",
    "        val = ((2 ** (1 - nu)) / gamma(nu)) * (x ** nu) * kv(nu, x)\n",
    "        # Safety: if kv underflowed to 0 or NaN, just treat as 0 correlation.\n",
    "        if not np.isfinite(val):\n",
    "            return 0.0\n",
    "        return float(val)\n",
    "\n",
    "\n",
    "def G_odd(h, a, u0, nu):\n",
    "    hnorm = (h @ h) ** 0.5\n",
    "    if hnorm == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        if d == 2:\n",
    "            Tp = chebyshev.Chebyshev.basis(p)\n",
    "            x = a * hnorm\n",
    "            val = (\n",
    "                ((-1) ** ((p - 1) / 2))\n",
    "                * (x ** nu)\n",
    "                * Tp((h @ u0) / hnorm)\n",
    "                * kv(p - nu, x)\n",
    "            )\n",
    "            if not np.isfinite(val):\n",
    "                return 0.0\n",
    "            return float(val)\n",
    "        # For d != 2 you'd implement the Gegenbauer-based version here.\n",
    "        raise NotImplementedError(\"G_odd currently only implemented for d=2.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# C2 block and full covariance\n",
    "# ============================================================\n",
    "def C2_block(h, a11, a22, a12, a12e, nu11, nu22, nu12, nu12e, rho, s1, s2, u0,theta):\n",
    "    C11 = s1 * s1 * G_even(h, a11, nu11)\n",
    "    C22 = s2 * s2 * G_even(h, a22, nu22)\n",
    "\n",
    "    even_part = G_even(h, a12,nu12)\n",
    "    odd_part = G_odd(h, a12e, u0, nu12e)\n",
    "\n",
    "    mix_plus = np.cos(theta) * even_part + np.sin(theta) * odd_part\n",
    "    mix_minus = np.cos(theta) * even_part - np.sin(theta) * odd_part\n",
    "\n",
    "    C12 = rho * s1 * s2 * mix_plus\n",
    "    C21 = rho * s1 * s2 * mix_minus\n",
    "\n",
    "    return np.array([[C11, C12],\n",
    "                     [C21, C22]])\n",
    "\n",
    "\n",
    "def build_cov_C2(loc, a11, a22, a12, a12e, nu11, nu22, nu12, nu12e, rho, s1, s2, u0,theta):\n",
    "    N = len(loc)\n",
    "    C = np.zeros((2 * N, 2 * N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            h = loc[j] - loc[i]\n",
    "            block = C2_block(h, a11, a22, a12, a12e, nu11, nu22, nu12, nu12e, rho, s1, s2, u0,theta)\n",
    "            C[2 * i:2 * i + 2, 2 * j:2 * j + 2] = block\n",
    "    return make_psd(C)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# NLL with multiple time replicates (full parameter vector)\n",
    "# ============================================================\n",
    "def total_nll_full_params(params, loc, y_list, s1, s2, u0):\n",
    "    \"\"\"\n",
    "    params = (a11, a22, a12, nu11, nu22, nu12, rho)\n",
    "    \"\"\"\n",
    "    a11, a22, a12, a12e, nu11, nu22, nu12e, nu12, rho, theta = params\n",
    "\n",
    "    # Basic constraints\n",
    "    if a11 < 0 or a22 < 0 or a12 < 0 or a12e < 0 or abs(rho) > 1:\n",
    "        return 1e20\n",
    "\n",
    "    C = build_cov_C2(loc, a11, a22, a12, a12e, nu11, nu22, nu12, nu12e, rho, s1, s2, u0, theta)\n",
    "    if np.isnan(C).any() or np.isinf(C).any():\n",
    "        return 1e20\n",
    "\n",
    "    try:\n",
    "        cF = cho_factor(C, check_finite=False)\n",
    "        logdet = 2.0 * np.sum(np.log(np.diag(cF[0])))\n",
    "    except Exception:\n",
    "        return 1e20\n",
    "\n",
    "    m = C.shape[0]        # 2N\n",
    "    R = len(y_list)       # number of time replicates\n",
    "\n",
    "    quad_sum = 0.0\n",
    "    try:\n",
    "        for y in y_list:\n",
    "            alpha = cho_solve(cF, y, check_finite=False)\n",
    "            quad_sum += float(y @ alpha)\n",
    "    except Exception:\n",
    "        return 1e20\n",
    "\n",
    "    nll = 0.5 * (quad_sum + R * logdet + R * m * np.log(2.0 * np.pi))\n",
    "    return nll\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Coordinate-wise grid search + L-BFGS-B refinement\n",
    "# ============================================================\n",
    "def coordinate_mle_C2_multi(loc, y_list, s1, s2, u0, init):\n",
    "    \"\"\"\n",
    "    1) Coordinate-wise grid search:\n",
    "       - 7 parameters: (a11, a22, a12, nu11, nu22, nu12, rho)\n",
    "       - Each has 5 grid values (linspace within bounds)\n",
    "       - At each step, pick best value for one parameter while holding others fixed\n",
    "       - Repeat sweeps until no improvement or max_sweeps reached\n",
    "\n",
    "    2) Continuous L-BFGS-B optimization from the best grid solution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Bounds for all 7 parameters\n",
    "    bounds = [\n",
    "        (3, 6000.0),   # a11\n",
    "        (3, 6000.0),   # a22\n",
    "        (3, 6000.0),   # a12\n",
    "        (3, 6000.0),   # a12e\n",
    "        (0.5, 50.0),     # nu11\n",
    "        (0.5, 50.0),     # nu22\n",
    "        (0.5, 50.0),     # nu12\n",
    "        (0.5, 50.0),     # nu12e\n",
    "        (-1, 1),    # rho\n",
    "        (0.01, 2.0*np.pi-0.01)     # theta\n",
    "    ]\n",
    "\n",
    "    param_names = [\"a11\", \"a22\", \"a12\", \"a12e\", \"nu11\", \"nu22\", \"nu12\", \"nu12e\", \"rho\", \"theta\"]\n",
    "\n",
    "    # Build n-point grids for each parameter\n",
    "    n_grid = 100\n",
    "    grid_vals = []\n",
    "    for (low, high) in bounds:\n",
    "        grid_vals.append(np.linspace(low, high, n_grid))\n",
    "\n",
    "    # Start from init, but clamp to bounds and snap to nearest grid point\n",
    "    current_params = np.array(init, dtype=float)\n",
    "    for k in range(len(bounds)):\n",
    "        low, high = bounds[k]\n",
    "        # clamp\n",
    "        current_params[k] = min(max(current_params[k], low), high)\n",
    "        # snap to nearest grid value\n",
    "        gv = grid_vals[k]\n",
    "        idx_nearest = np.argmin(np.abs(gv - current_params[k]))\n",
    "        current_params[k] = gv[idx_nearest]\n",
    "\n",
    "    current_nll = total_nll_full_params(current_params, loc, y_list, s1, s2, u0)\n",
    "    print(\"Initial (snapped) params:\", dict(zip(param_names, current_params)))\n",
    "    print(\"Initial NLL:\", current_nll)\n",
    "\n",
    "    max_sweeps = 5\n",
    "    tol_improve = 1e-6\n",
    "\n",
    "    for sweep in range(1, max_sweeps + 1):\n",
    "        print(f\"\\n===== Coordinate sweep {sweep}/{max_sweeps} =====\")\n",
    "        improved_this_sweep = False\n",
    "\n",
    "        for k in range(len(bounds)):\n",
    "            print(f\"  Optimizing parameter {k} ({param_names[k]})...\")\n",
    "\n",
    "            best_val_k = current_params[k]\n",
    "            best_nll_k = current_nll\n",
    "\n",
    "            # Try all grid values for parameter k\n",
    "            for candidate_val in grid_vals[k]:\n",
    "                trial_params = current_params.copy()\n",
    "                trial_params[k] = candidate_val\n",
    "                nll_val = total_nll_full_params(trial_params, loc, y_list, s1, s2, u0)\n",
    "\n",
    "                if nll_val < best_nll_k - tol_improve:\n",
    "                    best_nll_k = nll_val\n",
    "                    best_val_k = candidate_val\n",
    "\n",
    "            # Update if improved\n",
    "            if best_nll_k < current_nll - tol_improve:\n",
    "                print(f\"    Updated {param_names[k]}: {current_params[k]} -> {best_val_k}, \"\n",
    "                      f\"NLL {current_nll:.6f} -> {best_nll_k:.6f}\")\n",
    "                current_params[k] = best_val_k\n",
    "                current_nll = best_nll_k\n",
    "                improved_this_sweep = True\n",
    "            else:\n",
    "                print(f\"    No improvement for {param_names[k]} (kept {current_params[k]})\")\n",
    "\n",
    "        print(\"  End of sweep\", sweep, \"| current params:\",\n",
    "              dict(zip(param_names, current_params)),\n",
    "              \"| current NLL:\", current_nll)\n",
    "\n",
    "        if not improved_this_sweep:\n",
    "            print(\"\\nNo improvement in this sweep; stopping coordinate search.\")\n",
    "            break\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # After grid search: continuous L-BFGS-B step\n",
    "    # ---------------------------------------------\n",
    "    print(\"\\nCoordinate grid search complete.\")\n",
    "    print(\"Best grid parameters:\", dict(zip(param_names, current_params)))\n",
    "    print(\"Grid-based NLL:\", current_nll)\n",
    "\n",
    "    print(\"\\nStarting continuous optimization (L-BFGS-B)...\")\n",
    "\n",
    "    bounds_full = bounds  # same as above\n",
    "\n",
    "    res = minimize(\n",
    "        lambda params: total_nll_full_params(params, loc, y_list, s1, s2, u0),\n",
    "        x0=current_params,\n",
    "        bounds=bounds_full,\n",
    "        method=\"L-BFGS-B\",\n",
    "        options={'maxiter': 200, 'ftol': 1e-12}\n",
    "    )\n",
    "\n",
    "    print(\"\\nL-BFGS-B results:\")\n",
    "    print(\"Success:\", res.success)\n",
    "    print(\"Message:\", res.message)\n",
    "    print(\"Final parameters:\", res.x)\n",
    "    print(\"Final NLL:\", res.fun)\n",
    "\n",
    "    return tuple(res.x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "print(\"Loading multi-time U/V dataset...\")\n",
    "df = pd.read_csv(\"Data.csv\", parse_dates=[\"datetime\"])\n",
    "print(\"Total rows:\", len(df))\n",
    "\n",
    "# 1) Build spatial grid from the FIRST time slice\n",
    "times = np.sort(df[\"datetime\"].unique())\n",
    "t0 = times[0]\n",
    "df0 = df[df[\"datetime\"] == t0].copy()\n",
    "\n",
    "# Sort by (lat, lon) to get consistent ordering\n",
    "df0 = df0.sort_values([\"latitude\", \"longitude\"]).reset_index(drop=True)\n",
    "\n",
    "lat0 = df0[\"latitude\"].to_numpy()\n",
    "lon0 = df0[\"longitude\"].to_numpy()\n",
    "\n",
    "# Convert deg -> km\n",
    "lat_mean = np.mean(lat0)\n",
    "x_km = 111.0 * lon0 * np.cos(np.radians(lat_mean))\n",
    "y_km = 111.0 * lat0\n",
    "loc = np.column_stack([x_km, y_km])\n",
    "N = loc.shape[0]\n",
    "\n",
    "print(\"Spatial grid size N =\", N)\n",
    "\n",
    "# ---- Rescale to dimensionless coordinates ----\n",
    "D = squareform(pdist(loc))\n",
    "np.fill_diagonal(D, np.inf)\n",
    "nn_dists = D.min(axis=1)\n",
    "dist_scale = nn_dists.mean()  # typical nearest-neighbor spacing\n",
    "\n",
    "print(\"Average nearest-neighbor distance (km) =\", dist_scale)\n",
    "\n",
    "loc_scaled = loc / dist_scale\n",
    "print(\"Using rescaled locations (dimensionless) with typical spacing ~1.\")\n",
    "\n",
    "# 2) Build list of y_t vectors across time replicates\n",
    "y_list = []\n",
    "max_reps = 20  # upper limit on number of time replicates\n",
    "\n",
    "for tt in times:\n",
    "    if len(y_list) >= max_reps:\n",
    "        break\n",
    "\n",
    "    df_t = df[df[\"datetime\"] == tt].copy()\n",
    "    # Ensure same grid/order as df0 by merging\n",
    "    df_t = df_t.merge(\n",
    "        df0[[\"latitude\", \"longitude\"]],\n",
    "        on=[\"latitude\", \"longitude\"],\n",
    "        how=\"right\",\n",
    "        sort=False\n",
    "    )\n",
    "\n",
    "    # If any missing, skip this time\n",
    "    if df_t[\"u_std\"].isna().any() or df_t[\"v_std\"].isna().any():\n",
    "        continue\n",
    "\n",
    "    df_t = df_t.sort_values([\"latitude\", \"longitude\"]).reset_index(drop=True)\n",
    "\n",
    "    Y1 = df_t[\"u_std\"].to_numpy()\n",
    "    Y2 = df_t[\"v_std\"].to_numpy()\n",
    "\n",
    "    if len(Y1) != N or len(Y2) != N:\n",
    "        continue\n",
    "\n",
    "    y_t = np.zeros(2 * N)\n",
    "    y_t[0::2] = Y1\n",
    "    y_t[1::2] = Y2\n",
    "\n",
    "    y_list.append(y_t)\n",
    "\n",
    "R = len(y_list)\n",
    "print(\"Number of time replicates used:\", R)\n",
    "\n",
    "if R == 0:\n",
    "    raise RuntimeError(\"No complete time replicate found.\")\n",
    "\n",
    "# 3) Fit C2 with replicates, using rescaled loc\n",
    "s1 = s2 = 1.0\n",
    "u0 = np.array([1.0, 0.0])  # east–west\n",
    "\n",
    "print(\"\\nFitting C2 model with multiple time replicates (coordinate-wise grid + L-BFGS-B)...\\n\")\n",
    "\n",
    "init_params = (3.437, 3.572, 475.57, 0.0001, 29.9986, 29.9188, 1.5, 1.578, 0.26, np.pi/2)\n",
    "\n",
    "a11_hat, a22_hat, a12_hat, a12e_hat, nu11_hat, nu22_hat, nu12_hat,  nu12e_hat, rho_hat, theta_hat = coordinate_mle_C2_multi(\n",
    "    loc_scaled, y_list, s1, s2, u0, init_params\n",
    ")\n",
    "\n",
    "print(\"\\n===== FINAL ESTIMATES (C2, multi-time U/V) =====\")\n",
    "print(\"a11       =\", a11_hat)\n",
    "print(\"a22       =\", a22_hat)\n",
    "print(\"a12       =\", a12_hat)\n",
    "print(\"a12e       =\", a12e_hat)\n",
    "print(\"nu11      =\", nu11_hat)\n",
    "print(\"nu22      =\", nu22_hat)\n",
    "print(\"nu12      =\", nu12_hat)\n",
    "print(\"nu12e      =\", nu12e_hat)\n",
    "print(\"rho       =\", rho_hat)\n",
    "print(\"theta       =\", theta_hat)\n",
    "\n",
    "# 4) Model fit statistics: full NLL, AIC, BIC\n",
    "final_params = (a11_hat, a22_hat, a12_hat, a12e_hat, nu11_hat, nu22_hat, nu12_hat, nu12e_hat, rho_hat, theta_hat)\n",
    "NLL = total_nll_full_params(final_params, loc_scaled, y_list, s1, s2, u0)\n",
    "\n",
    "m = 2 * N\n",
    "k = 10  # a11, a22, a12, nu11, nu22, nu12, rho\n",
    "n_obs = R * m\n",
    "\n",
    "AIC = 2 * k + 2 * NLL\n",
    "BIC = k * np.log(n_obs) + 2 * NLL\n",
    "\n",
    "print(\"\\n===== MODEL FIT (C2, multi-time U/V) =====\")\n",
    "print(\"NLL =\", NLL)\n",
    "print(\"AIC =\", AIC)\n",
    "print(\"BIC =\", BIC)\n",
    "print(\"N   =\", N, \"locations; R =\", R, \"replicates; total obs =\", n_obs)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
